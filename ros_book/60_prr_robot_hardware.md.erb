---
title: "6: Robots"
desc: Going through the hardware
slides: true
---

## Robots are made up from many Subsystems

* Subsystems are 'represented' in the software
* Actuation (e.g. wheels)
* Sensing (e.g. cameras)
* Computing (e.g. brains)

<slide_break></slide_break>

### Concepts in Actuation

* 2 Wheel scenario
  * Differential drive: Turtlebot3
  * Turning by different speed on two or more wheels
  * Sometimes there is a caster
  * Can only move forward and backward.
* 4 Wheel Scenario
  * Not up and down or (directly) sideways
  * With more than 2 wheels, or a track - skid steering
  * Cars have "Ackerman" steering (4 wheels, 2 that can steer)
* Tracked Vehicles
  * Skid steering
* Holonomic - non-Holonomic
  * Holonomic - can move in any direction
* Manipulator Arms
  * Degrees of freedom
  * Coordinate transforms
  * Forward and reverse Kinematics
* Quadruped
  * Gait - trot, gallop, etc
  * Sensing vs. Non Sensing issues

<slide_break></slide_break>

## Case: Differential drive

### Lower Level

* Subscribes to `cmd_vel`
  * Desired translation and rotation speeds
  * Reverse kinematics tells us desired rotations per second for each wheel
* Publishes to `odom`
  * Forward kinematics tells us estimated actual motion (position and speed)
  * 'Dead Reckoning'

### Supporting hardware

* Two wheels + 1 or 2 casters
* Each wheel has motor and encoder
* Motor will go "faster" when given more current
* Encoder counts up for each rotation

### Algorithm

* PID control to minimize delta between desired and actual

## Sensors

### LiDAR

* Rotates and uses a laser to measure distance to nearest obstacle
* Returns a vector of values corresponding to the directions
* LiDAR's can operate in 2d (scan) or 3d (point cloud), ours is 2d

<%= callout("Limitation", " Operates in a plane, like a disk. Can't detect an obstacle above or below the plane!") %>

<slide_break></slide_break>

### Visual Cameras

* Webcam sees a color picture
* Matrix of dots, each dot has a color
* `Dot[x,y] = {r,g,b}`
* Data can be processed for example with `opencv`
* A lot of data and a lot of processing
* Bandwidth limits

<slide_break></slide_break>

### Depth Cameras

* Like a Microsoft Kinect
* In addition to `{r,g,b}` also has distance so we get `{r,g,b,d}`
* Useful for getting range measurements of an object detected through camera

<slide_break></slide_break>

## Computation

* Distributed environment, typically:
  1. roscore running onboard. on Raspberry pi
  1. Some additional ROS nodes running on Raspberry Pi
  1. More ROS nodes running on a laptop or other computer
* Workload is truly distributed across all of those
* Eventually we may have to have a much beefier computer running all three
* This would make the robot much more independent

<slide_break></slide_break>

### Actual Robots

* Our minRovers have:
  1. Arduino to control the motor. Also with various sensors, lights, and i/o ports. Board is from Robotis and is called OpenCR
  1. Raspberry Pi which runs Ubuntu Mate and ROS
